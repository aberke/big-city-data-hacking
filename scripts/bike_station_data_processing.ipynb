{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city chicago\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Processes the raw bike trip data to get information on bike dock locations\n",
    "and when the docks were placed in those locations.\n",
    "\n",
    "Desired output columns:\n",
    "\n",
    "id | first | last | name | lat | lon | rides\n",
    "\n",
    "where\n",
    "- id is the station's id\n",
    "- first is the earliest trip date for the station id\n",
    "- last is the latest trip date for the station id (included in case docks are removed)\n",
    "- name is the station's name\n",
    "- lat and lon are the latitude and longitude of the station's location\n",
    "- rides is a count of the number of rides found in the data -- it is used to remove dummy stations in the data.\n",
    "    only stations with more than RIDES_COUNT_THRESHOLD are included in output\n",
    "\n",
    "This script is abstracte to apply to multiple cities.\n",
    "DON'T FORGET: update the 'CITY' variable\n",
    "\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "# CITY = 'dc'\n",
    "# CITY = 'boston'\n",
    "# CITY = 'nyc'\n",
    "CITY = 'chicago'\n",
    "print('city', CITY)\n",
    "\n",
    "\n",
    "RIDES_COUNT_THRESHOLD = 100\n",
    "\n",
    "\n",
    "def get_filepath(city):\n",
    "    return '../data/' + city + '-bike/'\n",
    "\n",
    "\n",
    "def transform_date(date):\n",
    "    try:\n",
    "        dt = datetime.strptime(date.split(' ')[0], '%m/%d/%Y')\n",
    "    except ValueError:\n",
    "        # this dataset is so frustrating lol\n",
    "        dt = datetime.strptime(date.split(' ')[0], '%Y-%m-%d')\n",
    "        \n",
    "    return dt.strftime('%Y-%m-%d')\n",
    "\n",
    "def open_zipfile(zipfilename):\n",
    "    # Because someone dropped some gnarly mac osx files into their zips\n",
    "    zipfile = ZipFile(zipfilename)\n",
    "    filenames = [f.filename for f in zipfile.infolist()]\n",
    "    # Return the first file that can be opened  - not all of them have .csv suffix\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            df = pd.read_csv(zipfile.open(filename))\n",
    "            return df\n",
    "        except:\n",
    "            print('failed to open filename from zip', zipfilename, ': ', filename)\n",
    "            pass\n",
    "    raise Exception('unable to read a csv from zipfile %s' % zipfilename)\n",
    "\n",
    "def open_zipfile_dc(zipfilename):\n",
    "## DC bike files from 2012 to 2017 have 4 files for each quarter\n",
    "## this generator yields each of those files\n",
    "\n",
    "    zipfile = ZipFile(zipfilename)\n",
    "    files = [f.filename for f in zipfile.infolist()]\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            df = pd.read_csv(zipfile.open(filename))\n",
    "            yield df\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def open_zipfile_chicago(zipfilename):\n",
    "\n",
    "    zipfile = ZipFile(zipfilename)\n",
    "    files = [f.filename for f in zipfile.infolist()]\n",
    "    for filename in files:\n",
    "        if filename[:8] == '__MACOSX' or filename.endswith('txt') or 'Divvy_Stations_2' in filename:\n",
    "            continue\n",
    "        if '/' in filename:\n",
    "            if '/Divvy_Stations' in filename:\n",
    "                continue\n",
    "        try:\n",
    "            print(filename)\n",
    "            df = pd.read_csv(zipfile.open(filename))\n",
    "            yield df\n",
    "        except:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make a dict like \n",
    "{\"id\": {\"name\": \"\", \"lat\": \"\", \"lon\": \"\", \"first\": \"\", \"last\": \"\"}}\n",
    "where there is one entry for each id\n",
    "and where the start time is always the earliest found\n",
    "\n",
    "and then later transform it into a dict like\n",
    "\n",
    "{'id': [id1, id2, id3], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "\n",
    "to then make into a dataframe and save as a CSV\n",
    "\"\"\"\n",
    "\n",
    "# input file column names for indexing data with\n",
    "start_station_id = 'startstationid'\n",
    "start_station_name = 'startstationname'\n",
    "start_station_latitude = 'startstationlatitude'\n",
    "start_station_longitude = 'startstationlongitude'\n",
    "starttime = 'starttime'\n",
    "\n",
    "\n",
    "    \n",
    "# output file column names\n",
    "ID = 'id'\n",
    "NAME = 'name'\n",
    "LAT = 'lat'\n",
    "LON = 'lon'\n",
    "FIRST = 'first'\n",
    "LAST = 'last'\n",
    "RIDES = 'rides'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_stations_df(df):\n",
    "    # Because someone can't make data files with uniform column names\n",
    "    df.columns = df.columns.str.replace('number', 'id')  # 'Station Number' vs Station ID\n",
    "    df.columns = df.columns.str.replace('date', 'time')  # 'Start Date' vs 'Start Time'\n",
    "    \n",
    "    \n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('[\\ ]', '')\n",
    "    \n",
    "    # transform the dates\n",
    "    df[starttime] = df[starttime].apply(transform_date)\n",
    "    if CITY == \"boston\":\n",
    "        df = preprocess_boston_stations_df(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Some of the earlier bostons stations data does not include lat,lon coordinates.\n",
    "# These files contains the lat,lon coordinates (and other data) for station IDs\n",
    "hubway_stations_locations_filenames = [\n",
    "    \"Hubway_Stations_as_of_July_2017.csv\",\n",
    "    \"previous_Hubway_Stations_as_of_July_2017.csv\"\n",
    "]\n",
    "\n",
    "def get_hubway_stations_locations_df():\n",
    "    df = pd.DataFrame()\n",
    "    filenames = [get_filepath(CITY) + fname for fname in hubway_stations_locations_filenames]\n",
    "    for filename in filenames:\n",
    "        new_df = pd.read_csv(filename)    \n",
    "        hubway_stations_locations_column_names = {\n",
    "            \"Station ID\": start_station_id,\n",
    "            \"Latitude\": start_station_latitude,\n",
    "            \"Longitude\": start_station_longitude,\n",
    "        }\n",
    "        # Rename the column names to match the rides data that the locations data will be joined with\n",
    "        new_df.rename(columns=hubway_stations_locations_column_names, inplace=True)\n",
    "        df = new_df if df.empty else df.append(new_df)\n",
    "    df.drop_duplicates(subset=[start_station_id], inplace=True)\n",
    "    return df\n",
    "\n",
    "hubway_stations_locations_df = None\n",
    "if CITY == \"boston\":\n",
    "    hubway_stations_locations_df = get_hubway_stations_locations_df()\n",
    "\n",
    "\n",
    "def preprocess_boston_stations_df(df):\n",
    "    if start_station_latitude in df.columns:\n",
    "        return df\n",
    "    # Otherwise this is one of the datasets that is lacking lat, lon info.\n",
    "    # Add the lat,lon info\n",
    "    return hubway_stations_locations_df.merge(df, on=start_station_id)\n",
    "\n",
    "def choose_chicago_columns(filename):\n",
    "    if filename == 'Divvy_Trips_2018_Q1.zip' or filename == 'Divvy_Trips_2019_Q2.zip':\n",
    "        return ('03-rentalstartstationid','03-rentalstartstationname', '', '', '01-rentaldetailslocalstarttime' )\n",
    "    if filename[:5] == 'Divvy' and filename != 'Divvy_Trips_2020_Q1.zip':\n",
    "        if filename[:7] == 'Divvy_S' or int(filename[12:16]) < 2017:\n",
    "            return ('from_station_id', 'from_station_name', '', '', 'starttime')\n",
    "        return ('from_station_id', 'from_station_name', '', '', 'start_time')\n",
    "    return ('start_station_id', 'start_station_name', 'start_lat', 'start_lng', 'started_at')\n",
    "\n",
    "\n",
    "\n",
    "# hubway_stations_locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202004-divvy-tripdata.zip\n",
      "0 : handling file 202004-divvy-tripdata.zip\n",
      "202004-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202005-divvy-tripdata.zip\n",
      "1 : handling file 202005-divvy-tripdata.zip\n",
      "202005-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202006-divvy-tripdata.zip\n",
      "2 : handling file 202006-divvy-tripdata.zip\n",
      "202006-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202007-divvy-tripdata.zip\n",
      "3 : handling file 202007-divvy-tripdata.zip\n",
      "202007-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202008-divvy-tripdata.zip\n",
      "4 : handling file 202008-divvy-tripdata.zip\n",
      "202008-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202009-divvy-tripdata.zip\n",
      "5 : handling file 202009-divvy-tripdata.zip\n",
      "202009-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202010-divvy-tripdata.zip\n",
      "6 : handling file 202010-divvy-tripdata.zip\n",
      "202010-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202011-divvy-tripdata.zip\n",
      "7 : handling file 202011-divvy-tripdata.zip\n",
      "202011-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202012-divvy-tripdata.zip\n",
      "8 : handling file 202012-divvy-tripdata.zip\n",
      "202012-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202101-divvy-tripdata.zip\n",
      "9 : handling file 202101-divvy-tripdata.zip\n",
      "202101-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202102-divvy-tripdata.zip\n",
      "10 : handling file 202102-divvy-tripdata.zip\n",
      "202102-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202103-divvy-tripdata.zip\n",
      "11 : handling file 202103-divvy-tripdata.zip\n",
      "202103-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202104-divvy-tripdata.zip\n",
      "12 : handling file 202104-divvy-tripdata.zip\n",
      "202104-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202105-divvy-tripdata.zip\n",
      "13 : handling file 202105-divvy-tripdata.zip\n",
      "202105-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202106-divvy-tripdata.zip\n",
      "14 : handling file 202106-divvy-tripdata.zip\n",
      "202106-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202107-divvy-tripdata.zip\n",
      "15 : handling file 202107-divvy-tripdata.zip\n",
      "202107-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202108-divvy-tripdata.zip\n",
      "16 : handling file 202108-divvy-tripdata.zip\n",
      "202108-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202109-divvy-tripdata.zip\n",
      "17 : handling file 202109-divvy-tripdata.zip\n",
      "202109-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202110-divvy-tripdata.zip\n",
      "18 : handling file 202110-divvy-tripdata.zip\n",
      "202110-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202111-divvy-tripdata.zip\n",
      "19 : handling file 202111-divvy-tripdata.zip\n",
      "202111-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202112-divvy-tripdata.zip\n",
      "20 : handling file 202112-divvy-tripdata.zip\n",
      "202112-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202201-divvy-tripdata.zip\n",
      "21 : handling file 202201-divvy-tripdata.zip\n",
      "202201-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202202-divvy-tripdata.zip\n",
      "22 : handling file 202202-divvy-tripdata.zip\n",
      "202202-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202203-divvy-tripdata.zip\n",
      "23 : handling file 202203-divvy-tripdata.zip\n",
      "202203-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202204-divvy-tripdata.zip\n",
      "24 : handling file 202204-divvy-tripdata.zip\n",
      "202204-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202205-divvy-tripdata.zip\n",
      "25 : handling file 202205-divvy-tripdata.zip\n",
      "202205-divvy-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Stations_Trips_2013.zip\n",
      "26 : handling file Divvy_Stations_Trips_2013.zip\n",
      "Divvy_Stations_Trips_2013/Divvy_Trips_2013.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\576778883.py:91: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zipfile.open(filename))\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Stations_Trips_2014_Q1Q2.zip\n",
      "27 : handling file Divvy_Stations_Trips_2014_Q1Q2.zip\n",
      "Divvy_Trips_2014_Q1Q2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Stations_Trips_2014_Q3Q4.zip\n",
      "28 : handling file Divvy_Stations_Trips_2014_Q3Q4.zip\n",
      "Divvy_Stations_Trips_2014_Q3Q4/Divvy_Trips_2014-Q3-07.csv\n",
      "Divvy_Stations_Trips_2014_Q3Q4/Divvy_Trips_2014-Q3-0809.csv\n",
      "Divvy_Stations_Trips_2014_Q3Q4/Divvy_Trips_2014-Q4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2015-Q1Q2.zip\n",
      "29 : handling file Divvy_Trips_2015-Q1Q2.zip\n",
      "Divvy_Trips_2015-Q1.csv\n",
      "Divvy_Trips_2015-Q2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2015_Q3Q4.zip\n",
      "30 : handling file Divvy_Trips_2015_Q3Q4.zip\n",
      "Divvy_Trips_2015_Q4.csv\n",
      "Divvy_Trips_2015_09.csv\n",
      "Divvy_Trips_2015_08.csv\n",
      "Divvy_Trips_2015_07.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2016_Q1Q2.zip\n",
      "31 : handling file Divvy_Trips_2016_Q1Q2.zip\n",
      "Divvy_Trips_2016_Q1Q2/Divvy_Trips_2016_04.csv\n",
      "Divvy_Trips_2016_Q1Q2/Divvy_Trips_2016_05.csv\n",
      "Divvy_Trips_2016_Q1Q2/Divvy_Trips_2016_06.csv\n",
      "Divvy_Trips_2016_Q1Q2/Divvy_Trips_2016_Q1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2016_Q3Q4.zip\n",
      "32 : handling file Divvy_Trips_2016_Q3Q4.zip\n",
      "Divvy_Trips_2016_Q3.csv\n",
      "Divvy_Trips_2016_Q4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2017_Q1Q2.zip\n",
      "33 : handling file Divvy_Trips_2017_Q1Q2.zip\n",
      "Divvy_Trips_2017_Q1.csv\n",
      "Divvy_Trips_2017_Q2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2017_Q3Q4.zip\n",
      "34 : handling file Divvy_Trips_2017_Q3Q4.zip\n",
      "Divvy_Trips_2017_Q3.csv\n",
      "Divvy_Trips_2017_Q4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2018_Q1.zip\n",
      "35 : handling file Divvy_Trips_2018_Q1.zip\n",
      "Divvy_Trips_2018_Q1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2018_Q2.zip\n",
      "36 : handling file Divvy_Trips_2018_Q2.zip\n",
      "Divvy_Trips_2018_Q2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2018_Q3.zip\n",
      "37 : handling file Divvy_Trips_2018_Q3.zip\n",
      "Divvy_Trips_2018_Q3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2018_Q4.zip\n",
      "38 : handling file Divvy_Trips_2018_Q4.zip\n",
      "Divvy_Trips_2018_Q4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2019_Q1.zip\n",
      "39 : handling file Divvy_Trips_2019_Q1.zip\n",
      "Divvy_Trips_2019_Q1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2019_Q2.zip\n",
      "40 : handling file Divvy_Trips_2019_Q2.zip\n",
      "Divvy_Trips_2019_Q2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2019_Q3.zip\n",
      "41 : handling file Divvy_Trips_2019_Q3.zip\n",
      "Divvy_Trips_2019_Q3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2019_Q4.zip\n",
      "42 : handling file Divvy_Trips_2019_Q4.zip\n",
      "Divvy_Trips_2019_Q4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divvy_Trips_2020_Q1.zip\n",
      "43 : handling file Divvy_Trips_2020_Q1.zip\n",
      "Divvy_Trips_2020_Q1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_23932\\4204538325.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stations.csv\n",
      "stations.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>Eckhart Park</td>\n",
       "      <td>41.8964</td>\n",
       "      <td>-87.6610</td>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>44827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>Drake Ave &amp; Fullerton Ave</td>\n",
       "      <td>41.9244</td>\n",
       "      <td>-87.7154</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>13529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "      <td>McClurg Ct &amp; Erie St</td>\n",
       "      <td>41.8945</td>\n",
       "      <td>-87.6179</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>86932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216</td>\n",
       "      <td>California Ave &amp; Division St</td>\n",
       "      <td>41.9030</td>\n",
       "      <td>-87.6975</td>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>19399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>Rush St &amp; Hubbard St</td>\n",
       "      <td>41.8902</td>\n",
       "      <td>-87.6262</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>62760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                          name      lat      lon       first  \\\n",
       "0   86                  Eckhart Park  41.8964 -87.6610  2013-06-27   \n",
       "1  503     Drake Ave & Fullerton Ave  41.9244 -87.7154  2015-06-30   \n",
       "2  142          McClurg Ct & Erie St  41.8945 -87.6179  2015-06-30   \n",
       "3  216  California Ave & Division St  41.9030 -87.6975  2013-06-27   \n",
       "4  125          Rush St & Hubbard St  41.8902 -87.6262  2015-06-30   \n",
       "\n",
       "         last  rides  \n",
       "0  2020-11-07  44827  \n",
       "1  2020-11-07  13529  \n",
       "2  2020-11-07  86932  \n",
       "3  2020-11-07  19399  \n",
       "4  2020-11-07  62760  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAMES_TO_IGNORE = hubway_stations_locations_filenames + ['stations.csv'] + ['stations.json'] # + [more bad filenames here]\n",
    "\n",
    "\n",
    "def stations_dict_to_df(stations_dict):\n",
    "    new_dict = {\n",
    "        ID: [],\n",
    "        NAME: [],\n",
    "        LAT: [],\n",
    "        LON: [],\n",
    "        FIRST: [],\n",
    "        LAST: [],\n",
    "        RIDES: []\n",
    "    }\n",
    "    for station_id, station_dict in stations_dict.items():\n",
    "        new_dict[ID].append(station_id)\n",
    "        new_dict[NAME].append(station_dict[NAME])\n",
    "        new_dict[LAT].append(station_dict[LAT])\n",
    "        new_dict[LON].append(station_dict[LON])\n",
    "        new_dict[FIRST].append(station_dict[FIRST])\n",
    "        new_dict[LAST].append(station_dict[LAST])\n",
    "        new_dict[RIDES].append(station_dict[RIDES])\n",
    "    \n",
    "    return pd.DataFrame.from_dict(new_dict)\n",
    "    \n",
    "\n",
    "\n",
    "stations_dict = dict()\n",
    "needs_lat_lon = set()\n",
    "directory = get_filepath(CITY)\n",
    "files_count = 0\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    print(filename)\n",
    "    if filename in FILENAMES_TO_IGNORE:# or filename[:6] not in ['202102']:\n",
    "        continue\n",
    "    if filename[:4] in ['2021', '2022'] and filename[:6] not in ['202101'] and CITY == 'boston' or (filename[:4] in ['2020', '2021', '2022'] and filename[:6] not in ['202001', '202002', '202003']) and CITY == 'dc' :\n",
    "        start_station_id = 'start_station_id'\n",
    "        start_station_name = 'start_station_name'\n",
    "        start_station_latitude = 'start_lat'\n",
    "        start_station_longitude = 'start_lng'\n",
    "        starttime = 'started_at'\n",
    "    elif CITY != 'dc' and CITY != 'chicago':\n",
    "        start_station_id = 'startstationid'\n",
    "        start_station_name = 'startstationname'\n",
    "        start_station_latitude = 'startstationlatitude'\n",
    "        start_station_longitude = 'startstationlongitude'\n",
    "        starttime = 'starttime'\n",
    "    elif CITY == 'chicago':\n",
    "        start_station_id, start_station_name, start_station_latitude, start_station_longitude, starttime = choose_chicago_columns(filename)\n",
    "    else:\n",
    "        start_station_id = 'startstationid'\n",
    "        start_station_name = 'startstation'\n",
    "        start_station_latitude = \"\"\n",
    "        start_station_longitude = \"\"\n",
    "        starttime = \"starttime\"\n",
    "\n",
    "\n",
    "    fullfilename = directory + filename\n",
    "    print(files_count, ': handling file', filename)\n",
    "    files_count+=1\n",
    "    \n",
    "    if filename.endswith(\".csv\"):\n",
    "        stations_dfs = [pd.read_csv(fullfilename)]\n",
    "    elif filename.endswith(\".zip\") and CITY == 'ny':\n",
    "        stations_dfs = [open_zipfile(fullfilename)]\n",
    "    elif filename.endswith(\".zip\") and CITY == 'dc':\n",
    "        stations_dfs = [df for df in open_zipfile_dc(fullfilename)]\n",
    "    elif filename.endswith(\".zip\") and CITY == 'chicago':\n",
    "        stations_dfs = [df for df in open_zipfile_chicago(fullfilename)]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    for stations_df in stations_dfs:\n",
    "\n",
    "        stations_df = preprocess_stations_df(stations_df)\n",
    "        \n",
    "        unique_station_ids = stations_df[start_station_id].unique()\n",
    "        for station_id in unique_station_ids:\n",
    "            station_df = stations_df[stations_df[start_station_id] == station_id]\n",
    "            \n",
    "            if station_id not in stations_dict:\n",
    "                try:\n",
    "                    stations_dict[station_id] = {\n",
    "                        NAME: station_df[start_station_name].iloc[0], \n",
    "                        LAT: station_df[start_station_latitude].iloc[0],\n",
    "                        LON: station_df[start_station_longitude].iloc[0], \n",
    "                        FIRST: station_df[starttime].iloc[0], \n",
    "                        LAST: station_df[starttime].iloc[0],\n",
    "                        RIDES: 0,\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    \n",
    "                    if type(e).__name__ == 'KeyError':\n",
    "                        \n",
    "                        stations_dict[station_id] = {\n",
    "                            NAME: station_df[start_station_name].iloc[0], \n",
    "                            LAT: 0,\n",
    "                            LON: 0,\n",
    "                            FIRST: station_df[starttime].iloc[0], \n",
    "                            LAST: station_df[starttime].iloc[0],\n",
    "                            RIDES: 0,\n",
    "                        }\n",
    "                        needs_lat_lon.add(station_id)\n",
    "                    else:    \n",
    "                        continue\n",
    "            if station_id in needs_lat_lon and starttime == 'started_at':\n",
    "                stations_dict[station_id][LAT] = station_df[start_station_latitude].iloc[0]\n",
    "                stations_dict[station_id][LON] = station_df[start_station_longitude].iloc[0]\n",
    "                needs_lat_lon.remove(station_id)\n",
    "            rides_count = len(station_df.index)\n",
    "            stations_dict[station_id][RIDES] += rides_count\n",
    "            station_df = station_df.sort_values(by=[starttime])\n",
    "            if (station_df[starttime].iloc[0] < stations_dict[station_id][FIRST]):\n",
    "                stations_dict[station_id][FIRST] = stations_df[starttime].iloc[0]\n",
    "            if (station_df[starttime].iloc[-1] > stations_dict[station_id][LAST]):\n",
    "                stations_dict[station_id][LAST] = stations_df[starttime].iloc[-1]\n",
    "\n",
    "\n",
    "stations_df = stations_dict_to_df(stations_dict)\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 370 bad stations that each have less than 100 rides from stations data\n",
      "removing 16 more stations for not having latitude or longitude\n"
     ]
    }
   ],
   "source": [
    "# Transform the stations_df\n",
    "\n",
    "# Remove dummy stations (there are test stations in the data)\n",
    "# Remove stations with less than RIDES_COUNT_THRESHOLD rides\n",
    "bad_stations_df = stations_df[stations_df[RIDES] < RIDES_COUNT_THRESHOLD]\n",
    "print('removing %d bad stations that each have less than %d rides from stations data' % (bad_stations_df.shape[0], RIDES_COUNT_THRESHOLD))\n",
    "stations_df = stations_df[stations_df[RIDES] >= RIDES_COUNT_THRESHOLD]\n",
    "## Remove stations that do not have a latitude and longitude measure\n",
    "bad_stations_2 = stations_df[stations_df[LAT] == 0]\n",
    "print(f'removing {bad_stations_2.shape[0]} more stations for not having latitude or longitude')\n",
    "stations_df = stations_df[stations_df[LAT] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>562</td>\n",
       "      <td>Racine Ave &amp; 61st St</td>\n",
       "      <td>41.783200</td>\n",
       "      <td>-87.654400</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>651</td>\n",
       "      <td>Michigan Ave &amp; 71st St</td>\n",
       "      <td>41.765300</td>\n",
       "      <td>-87.621700</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>648</td>\n",
       "      <td>Carpenter St &amp; 63rd St</td>\n",
       "      <td>41.779900</td>\n",
       "      <td>-87.650900</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>652</td>\n",
       "      <td>Rhodes Ave &amp; 71st St</td>\n",
       "      <td>41.766000</td>\n",
       "      <td>-87.611700</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>647</td>\n",
       "      <td>Elizabeth St &amp; 59th St</td>\n",
       "      <td>41.786700</td>\n",
       "      <td>-87.655900</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>665</td>\n",
       "      <td>South Chicago Ave &amp; Elliot Ave</td>\n",
       "      <td>41.747363</td>\n",
       "      <td>-87.580046</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>681.0</td>\n",
       "      <td>Halsted St &amp; 78th St</td>\n",
       "      <td>41.752487</td>\n",
       "      <td>-87.643902</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>674.0</td>\n",
       "      <td>Michigan Ave &amp; 71st St</td>\n",
       "      <td>41.765286</td>\n",
       "      <td>-87.621748</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>677.0</td>\n",
       "      <td>Stewart Ave &amp; 83rd St</td>\n",
       "      <td>41.743717</td>\n",
       "      <td>-87.634088</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>679.0</td>\n",
       "      <td>Ashland Ave &amp; 73rd St</td>\n",
       "      <td>41.761225</td>\n",
       "      <td>-87.663361</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                            name        lat        lon       first  \\\n",
       "545    562            Racine Ave & 61st St  41.783200 -87.654400  2016-09-30   \n",
       "572    651          Michigan Ave & 71st St  41.765300 -87.621700  2018-10-01   \n",
       "593    648          Carpenter St & 63rd St  41.779900 -87.650900  2018-10-01   \n",
       "603    652            Rhodes Ave & 71st St  41.766000 -87.611700  2019-04-01   \n",
       "609    647          Elizabeth St & 59th St  41.786700 -87.655900  2019-01-01   \n",
       "611    665  South Chicago Ave & Elliot Ave  41.747363 -87.580046  2019-01-01   \n",
       "612  681.0            Halsted St & 78th St  41.752487 -87.643902  2020-07-09   \n",
       "613  674.0          Michigan Ave & 71st St  41.765286 -87.621748  2020-07-09   \n",
       "614  677.0           Stewart Ave & 83rd St  41.743717 -87.634088  2020-07-09   \n",
       "616  679.0           Ashland Ave & 73rd St  41.761225 -87.663361  2020-07-31   \n",
       "\n",
       "           last  rides  \n",
       "545  2020-10-31     59  \n",
       "572  2020-06-06     24  \n",
       "593  2020-11-07     40  \n",
       "603  2020-11-07     74  \n",
       "609  2020-10-31     36  \n",
       "611  2020-11-07     44  \n",
       "612  2020-11-07     54  \n",
       "613  2020-11-07     92  \n",
       "614  2020-11-07     62  \n",
       "616  2020-11-07     33  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_stations_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For the boston hubway/blue bikes data there will be duplicates because\n",
    "when management changed from hubway to Bluebikes, the data fromat did too\n",
    "This includes the station id/numbers and names AND lat/lon!\n",
    "Task: deduplicate stations\n",
    "\n",
    "Idea to understand data: sort the stations so the potential duplicates are next to each other\n",
    "when merging/deduping data make sure to keep the earliest first and the latest last.\n",
    "\n",
    "approach to deduplicating stations:\n",
    "- normalize names and add new temporary column with normalized name\n",
    "- get list of unique normalized names\n",
    "- for each name:\n",
    "    make a df for that name, sorted by [first, last]\n",
    "    update main df to replace entries with that name with:\n",
    "        first first\n",
    "        last last\n",
    "        last name\n",
    "        rides as sum of rides\n",
    "    sort main df by [name, first] and drop duplicates (duplicates on normalized name)\n",
    "    remove normalized name column\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "NORMALIZED_NAME = 'normalized_name'\n",
    "\n",
    "def normalized_station_name(name):\n",
    "    normalized_name = name.lower()\n",
    "    normalized_name = normalized_name.replace(\"former\",  \"\").replace(\" \", \"\")\n",
    "    normalized_name = re.sub(r'[^a-z0-9]','', normalized_name)\n",
    "    return normalized_name\n",
    "\n",
    "if CITY == 'boston':\n",
    "    stations_df[NORMALIZED_NAME] = stations_df[NAME].apply(normalized_station_name)\n",
    "    normalized_names = stations_df[NORMALIZED_NAME]\n",
    "    print(normalized_names.shape[0], ' names')\n",
    "    unique_normalized_names = stations_df[NORMALIZED_NAME].unique()\n",
    "    print(unique_normalized_names.shape[0], ' unique normalized names') #, unique_normalized_names)\n",
    "\n",
    "\n",
    "    n = 0\n",
    "    for normalized_name in unique_normalized_names:\n",
    "        print(n, 'handling name', normalized_name)\n",
    "        n+=1\n",
    "        name_df = stations_df[stations_df[NORMALIZED_NAME] == normalized_name]\n",
    "        name_df.sort_values(by=[FIRST, LAST], inplace=True)\n",
    "        first = name_df[FIRST].iloc[0]\n",
    "        last = name_df[LAST].iloc[-1]\n",
    "        name = name_df[NAME].iloc[-1]\n",
    "        rides = name_df[RIDES].sum()\n",
    "        update_condition = (stations_df[NORMALIZED_NAME] == normalized_name)\n",
    "        stations_df.loc[update_condition, [FIRST, LAST, NAME, RIDES]] = first, last, name, rides\n",
    "\n",
    "    stations_dropped_duplicates_df = stations_df.drop_duplicates(subset=[NORMALIZED_NAME])\n",
    "    print('dropped %s rows based on duplicate names' % (int(stations_df.shape[0]) - int(stations_dropped_duplicates_df.shape[0])))\n",
    "    stations_dropped_duplicates_df.drop(labels=[NORMALIZED_NAME], axis=1, inplace=True)\n",
    "    \n",
    "    stations_df = stations_dropped_duplicates_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote data to  ../data/chicago-bike/stations.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data to CSV\n",
    "save_to_csvfilename = directory + 'stations.csv'\n",
    "stations_df.to_csv(save_to_csvfilename)\n",
    "print('wrote data to ', save_to_csvfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to stations.json\n"
     ]
    }
   ],
   "source": [
    "# Save the data to JSON that will be used in web app\n",
    "import json\n",
    "\n",
    "stations = []\n",
    "for index, row in stations_df.iterrows():\n",
    "    # Transform the date\n",
    "    date = row[5]\n",
    "    \n",
    "    stations.append({\n",
    "        ID: str(row[ID]),\n",
    "        NAME: row[NAME],\n",
    "        LAT: row[LAT],\n",
    "        LON: row[LON],\n",
    "        FIRST: transform_date(row[FIRST]),\n",
    "        LAST: transform_date(row[LAST]),\n",
    "    })\n",
    "\n",
    "json = json.dumps(stations)\n",
    "\n",
    "save_to_jsonfilename = directory + 'stations.json'\n",
    "with open(save_to_jsonfilename, 'w') as f:\n",
    "    f.write(json)\n",
    "print(\"Data written to stations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31208</td>\n",
       "      <td>M St &amp; New Jersey Ave SE</td>\n",
       "      <td>38.87630</td>\n",
       "      <td>-77.003700</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>96870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31209</td>\n",
       "      <td>1st &amp; N St  SE</td>\n",
       "      <td>38.87430</td>\n",
       "      <td>-77.005700</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>71502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31600</td>\n",
       "      <td>5th &amp; K St NW</td>\n",
       "      <td>38.90304</td>\n",
       "      <td>-77.019027</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>271413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31100</td>\n",
       "      <td>19th St &amp; Pennsylvania Ave NW</td>\n",
       "      <td>38.90030</td>\n",
       "      <td>-77.042900</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>106021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31109</td>\n",
       "      <td>7th &amp; T St NW</td>\n",
       "      <td>38.91550</td>\n",
       "      <td>-77.022200</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>192171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                           name       lat        lon       first  \\\n",
       "0  31208       M St & New Jersey Ave SE  38.87630 -77.003700  2010-09-20   \n",
       "1  31209                 1st & N St  SE  38.87430 -77.005700  2010-09-20   \n",
       "2  31600                  5th & K St NW  38.90304 -77.019027  2010-09-20   \n",
       "3  31100  19th St & Pennsylvania Ave NW  38.90030 -77.042900  2010-09-20   \n",
       "4  31109                  7th & T St NW  38.91550 -77.022200  2010-09-20   \n",
       "\n",
       "         last   rides  \n",
       "0  2022-05-29   96870  \n",
       "1  2022-05-29   71502  \n",
       "2  2022-05-29  271413  \n",
       "3  2022-05-29  106021  \n",
       "4  2022-05-29  192171  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "639955f742b38ffeb680f958c1dc9e296c7318d3e6d17e3c3dcc92b8320cf293"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
