{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processes the raw bike trip data to get information on bike dock locations\n",
    "and when the docks were placed in those locations.\n",
    "\n",
    "Desired output columns:\n",
    "\n",
    "id | first | last | name | lat | lon\n",
    "\n",
    "where\n",
    "- id is the station's id\n",
    "- first is the earliest trip date for the station id\n",
    "- last is the latest trip date for the station id (included in case docks are removed)\n",
    "- name is the station's name\n",
    "- lat and lon are the latitude and longitude of the station's location\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_filepath(city):\n",
    "    return '../data/' + city + '-bike/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling file 201309-citibike-tripdata.zip\n",
      "handling file 201608-citibike-tripdata.zip\n",
      "handling file 201807-citibike-tripdata.csv.zip\n",
      "handling file 201708-citibike-tripdata.csv.zip\n",
      "handling file 201905-citibike-tripdata.csv.zip\n",
      "handling file 201510-citibike-tripdata.zip\n",
      "handling file 201405-citibike-tripdata.zip\n",
      "handling file 201812-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201506-citibike-tripdata.zip\n",
      "handling file 201712-citibike-tripdata.csv.zip\n",
      "handling file 201902-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201512-citibike-tripdata.zip\n",
      "handling file 201411-citibike-tripdata.zip\n",
      "handling file 201808-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201407-citibike-tripdata.zip\n",
      "handling file 201504-citibike-tripdata.zip\n",
      "handling file 201707-citibike-tripdata.csv.zip\n",
      "handling file 201602-citibike-tripdata.zip\n",
      "handling file 201702-citibike-tripdata.csv.zip\n",
      "handling file 201612-citibike-tripdata.zip\n",
      "handling file 201805-citibike-tripdata.csv.zip\n",
      "handling file 201604-citibike-tripdata.zip\n",
      "handling file 201502-citibike-tripdata.zip\n",
      "handling file 201401-citibike-tripdata.zip\n",
      "handling file 201907-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201409-citibike-tripdata.zip\n",
      "handling file 201810-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201403-citibike-tripdata.zip\n",
      "handling file 201710-citibike-tripdata.csv.zip\n",
      "handling file 201311-citibike-tripdata.zip\n",
      "handling file 201610-citibike-tripdata.zip\n",
      "handling file 201606-citibike-tripdata.zip\n",
      "handling file 201307-citibike-tripdata.zip\n",
      "handling file 201508-citibike-tripdata.zip\n",
      "handling file 201802-citibike-tripdata.csv.zip\n",
      "handling file 201705-citibike-tripdata.csv.zip\n",
      "handling file 201601-citibike-tripdata.zip\n",
      "handling file 201803-citibike-tripdata.csv.zip\n",
      "handling file 201704-citibike-tripdata.csv.zip\n",
      "handling file 201404-citibike-tripdata.zip\n",
      "handling file 201507-citibike-tripdata.zip\n",
      "handling file 201511-citibike-tripdata.zip\n",
      "handling file 201412-citibike-tripdata.zip\n",
      "handling file 201901-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201308-citibike-tripdata.zip\n",
      "handling file 201609-citibike-tripdata.zip\n",
      "handling file 201711-citibike-tripdata.csv.zip\n",
      "handling file 201406-citibike-tripdata.zip\n",
      "handling file 201505-citibike-tripdata.zip\n",
      "handling file 201811-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201410-citibike-tripdata.zip\n",
      "handling file 201603-citibike-tripdata.zip\n",
      "handling file 201906-citibike-tripdata.csv.zip\n",
      "handling file 201703-citibike-tripdata.csv.zip\n",
      "handling file 201804-citibike-tripdata.csv.zip\n",
      "handling file 201801-citibike-tripdata.csv.zip\n",
      "handling file 201706-citibike-tripdata.csv.zip\n",
      "handling file 201809-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201408-citibike-tripdata.zip\n",
      "handling file 201605-citibike-tripdata.zip\n",
      "handling file 201903-citibike-tripdata.csv.zip\n",
      "found nan\n",
      "handling file 201312-citibike-tripdata.zip\n",
      "handling file 201503-citibike-tripdata.zip\n",
      "handling file 201509-citibike-tripdata.zip\n",
      "handling file 201904-citibike-tripdata.csv.zip\n",
      "handling file 201501-citibike-tripdata.zip\n",
      "handling file 201709-citibike-tripdata.csv.zip\n",
      "handling file 201402-citibike-tripdata.zip\n",
      "handling file 201607-citibike-tripdata.zip\n",
      "handling file 201306-citibike-tripdata.zip\n",
      "handling file 201701-citibike-tripdata.csv.zip\n",
      "handling file 201310-citibike-tripdata.zip\n",
      "handling file 201806-citibike-tripdata.csv.zip\n",
      "handling file 201611-citibike-tripdata.zip\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254.0</td>\n",
       "      <td>W 11 St &amp; 6 Ave</td>\n",
       "      <td>40.735324</td>\n",
       "      <td>-73.998004</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>9/30/2015 23:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.0</td>\n",
       "      <td>Cleveland Pl &amp; Spring St</td>\n",
       "      <td>40.721816</td>\n",
       "      <td>-73.997203</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>9/30/2015 23:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352.0</td>\n",
       "      <td>W 56 St &amp; 6 Ave</td>\n",
       "      <td>40.763406</td>\n",
       "      <td>-73.977225</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>9/30/2015 23:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>490.0</td>\n",
       "      <td>8 Ave &amp; W 33 St</td>\n",
       "      <td>40.751551</td>\n",
       "      <td>-73.993934</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>9/30/2015 23:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236.0</td>\n",
       "      <td>St Marks Pl &amp; 2 Ave</td>\n",
       "      <td>40.728419</td>\n",
       "      <td>-73.987140</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>9/30/2015 23:59:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                      name        lat        lon          first  \\\n",
       "0  254.0           W 11 St & 6 Ave  40.735324 -73.998004  1/1/2015 0:01   \n",
       "1  151.0  Cleveland Pl & Spring St  40.721816 -73.997203  1/1/2015 0:01   \n",
       "2  352.0           W 56 St & 6 Ave  40.763406 -73.977225  1/1/2015 0:01   \n",
       "3  490.0           8 Ave & W 33 St  40.751551 -73.993934  1/1/2015 0:01   \n",
       "4  236.0       St Marks Pl & 2 Ave  40.728419 -73.987140  1/1/2015 0:01   \n",
       "\n",
       "                 last  \n",
       "0  9/30/2015 23:59:57  \n",
       "1  9/30/2015 23:59:57  \n",
       "2  9/30/2015 23:59:57  \n",
       "3  9/30/2015 23:59:57  \n",
       "4  9/30/2015 23:59:57  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# input file column names for indexing data with\n",
    "start_station_id = 'startstationid'\n",
    "start_station_name = 'startstationname'\n",
    "start_station_latitude = 'startstationlatitude'\n",
    "start_station_longitude = 'startstationlongitude'\n",
    "starttime = 'starttime'\n",
    "\n",
    "# output file column names\n",
    "ID = 'id'\n",
    "NAME = 'name'\n",
    "LAT = 'lat'\n",
    "LON = 'lon'\n",
    "FIRST = 'first'\n",
    "LAST = 'last'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "make a dict like \n",
    "{\"id\": {\"name\": \"\", \"lat\": \"\", \"lon\": \"\", \"first\": \"\", \"last\": \"\"}}\n",
    "where there is one entry for each id\n",
    "and where the start time is always the earliest found\n",
    "\n",
    "and then later transform it into a dict like\n",
    "\n",
    "{'id': [id1, id2, id3], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "\n",
    "to then make into a dataframe and save as a CSV\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def stations_dict_to_df(stations_dict):\n",
    "    new_dict = {\n",
    "        ID: [],\n",
    "        NAME: [],\n",
    "        LAT: [],\n",
    "        LON: [],\n",
    "        FIRST: [],\n",
    "        LAST: []\n",
    "    }\n",
    "    for station_id, station_dict in stations_dict.items():\n",
    "        new_dict[ID].append(station_id)\n",
    "        new_dict[NAME].append(station_dict[NAME])\n",
    "        new_dict[LAT].append(station_dict[LAT])\n",
    "        new_dict[LON].append(station_dict[LON])\n",
    "        new_dict[FIRST].append(station_dict[FIRST])\n",
    "        new_dict[LAST].append(station_dict[LAST])\n",
    "    \n",
    "    return pd.DataFrame.from_dict(new_dict)\n",
    "    \n",
    "\n",
    "\n",
    "stations_dict = dict()\n",
    "\n",
    "directory = get_filepath('nyc')\n",
    "\n",
    "for zipfilename in os.listdir(directory):\n",
    "    if not zipfilename.endswith(\".zip\"):\n",
    "        continue\n",
    "        \n",
    "    print('handling file', zipfilename)\n",
    "    fullzipfilename = directory + zipfilename\n",
    "    # Because someone dropped some gnarly mac osx files into their zips\n",
    "    zipfile = ZipFile(fullzipfilename)\n",
    "    csvfilename = [f.filename for f in zipfile.infolist() if f.filename.endswith('.csv')][0]\n",
    "    \n",
    "    stations_df = pd.read_csv(zipfile.open(csvfilename))\n",
    "    # Because someone can't make data files with uniform column names\n",
    "    stations_df.columns = map(str.lower, stations_df.columns)\n",
    "    stations_df.columns = stations_df.columns.str.replace('[\\ ]', '')\n",
    "\n",
    "    unique_station_ids = stations_df[start_station_id].unique()\n",
    "    for station_id in unique_station_ids:\n",
    "        if math.isnan(station_id):\n",
    "            print('found nan')\n",
    "            continue\n",
    "        station_df = stations_df[stations_df[start_station_id] == station_id]\n",
    "        if station_id not in stations_dict:\n",
    "            stations_dict[station_id] = {\n",
    "                NAME: station_df[start_station_name].iloc[0], \n",
    "                LAT: station_df[start_station_latitude].iloc[0],\n",
    "                LON: station_df[start_station_longitude].iloc[0], \n",
    "                FIRST: station_df[starttime].iloc[0], \n",
    "                LAST: station_df[starttime].iloc[0], \n",
    "            }\n",
    "        station_df = station_df.sort_values(by=[starttime])\n",
    "        if (station_df[starttime].iloc[0] < stations_dict[station_id]['first']):\n",
    "            stations_dict[station_id]['first'] = stations_df[starttime].iloc[0]\n",
    "        if (station_df[starttime].iloc[-1] > stations_dict[station_id]['last']):\n",
    "            stations_dict[station_id]['last'] = stations_df[starttime].iloc[-1]\n",
    "\n",
    "\n",
    "stations_df = stations_dict_to_df(stations_dict)\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-ff08478f3a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msave_to_csvfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'stations.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstations_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to_csvfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# Save the data to CSV\n",
    "\n",
    "save_to_csvfilename = directory + 'stations.csv'\n",
    "stations_df.to_csv(save_to_csvfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
