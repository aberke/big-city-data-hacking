{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city dc\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Processes the raw bike trip data to get information on bike dock locations\n",
    "and when the docks were placed in those locations.\n",
    "\n",
    "Desired output columns:\n",
    "\n",
    "id | first | last | name | lat | lon | rides\n",
    "\n",
    "where\n",
    "- id is the station's id\n",
    "- first is the earliest trip date for the station id\n",
    "- last is the latest trip date for the station id (included in case docks are removed)\n",
    "- name is the station's name\n",
    "- lat and lon are the latitude and longitude of the station's location\n",
    "- rides is a count of the number of rides found in the data -- it is used to remove dummy stations in the data.\n",
    "    only stations with more than RIDES_COUNT_THRESHOLD are included in output\n",
    "\n",
    "This script is abstracte to apply to multiple cities.\n",
    "DON'T FORGET: update the 'CITY' variable\n",
    "\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "CITY = 'dc'\n",
    "# CITY = 'boston'\n",
    "# CITY = 'nyc'\n",
    "print('city', CITY)\n",
    "\n",
    "\n",
    "RIDES_COUNT_THRESHOLD = 100\n",
    "\n",
    "\n",
    "def get_filepath(city):\n",
    "    return '../data/' + city + '-bike/'\n",
    "\n",
    "\n",
    "def transform_date(date):\n",
    "    try:\n",
    "        dt = datetime.strptime(date.split(' ')[0], '%m/%d/%Y')\n",
    "    except ValueError:\n",
    "        # this dataset is so frustrating lol\n",
    "        dt = datetime.strptime(date.split(' ')[0], '%Y-%m-%d')\n",
    "        \n",
    "    return dt.strftime('%Y-%m-%d')\n",
    "\n",
    "def open_zipfile(zipfilename):\n",
    "    # Because someone dropped some gnarly mac osx files into their zips\n",
    "    zipfile = ZipFile(zipfilename)\n",
    "    filenames = [f.filename for f in zipfile.infolist()]\n",
    "    # Return the first file that can be opened  - not all of them have .csv suffix\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            df = pd.read_csv(zipfile.open(filename))\n",
    "            return df\n",
    "        except:\n",
    "            print('failed to open filename from zip', zipfilename, ': ', filename)\n",
    "            pass\n",
    "    raise Exception('unable to read a csv from zipfile %s' % zipfilename)\n",
    "\n",
    "def open_zipfile_dc(zipfilename):\n",
    "    zipfile = ZipFile(zipfilename)\n",
    "    files = [f.filename for f in zipfile.infolist()]\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            df = pd.read_csv(zipfile.open(filename))\n",
    "            yield df\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make a dict like \n",
    "{\"id\": {\"name\": \"\", \"lat\": \"\", \"lon\": \"\", \"first\": \"\", \"last\": \"\"}}\n",
    "where there is one entry for each id\n",
    "and where the start time is always the earliest found\n",
    "\n",
    "and then later transform it into a dict like\n",
    "\n",
    "{'id': [id1, id2, id3], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "\n",
    "to then make into a dataframe and save as a CSV\n",
    "\"\"\"\n",
    "\n",
    "# input file column names for indexing data with\n",
    "start_station_id = 'startstationid'\n",
    "start_station_name = 'startstationname'\n",
    "start_station_latitude = 'startstationlatitude'\n",
    "start_station_longitude = 'startstationlongitude'\n",
    "starttime = 'starttime'\n",
    "\n",
    "\n",
    "    \n",
    "# output file column names\n",
    "ID = 'id'\n",
    "NAME = 'name'\n",
    "LAT = 'lat'\n",
    "LON = 'lon'\n",
    "FIRST = 'first'\n",
    "LAST = 'last'\n",
    "RIDES = 'rides'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_stations_df(df):\n",
    "    # Because someone can't make data files with uniform column names\n",
    "    df.columns = df.columns.str.replace('number', 'id')  # 'Station Number' vs Station ID\n",
    "    df.columns = df.columns.str.replace('date', 'time')  # 'Start Date' vs 'Start Time'\n",
    "    \n",
    "    \n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('[\\ ]', '')\n",
    "    \n",
    "    # transform the dates\n",
    "    df[starttime] = df[starttime].apply(transform_date)\n",
    "    if CITY == \"boston\":\n",
    "        df = preprocess_boston_stations_df(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Some of the earlier bostons stations data does not include lat,lon coordinates.\n",
    "# These files contains the lat,lon coordinates (and other data) for station IDs\n",
    "hubway_stations_locations_filenames = [\n",
    "    \"Hubway_Stations_as_of_July_2017.csv\",\n",
    "    \"previous_Hubway_Stations_as_of_July_2017.csv\"\n",
    "]\n",
    "\n",
    "def get_hubway_stations_locations_df():\n",
    "    df = pd.DataFrame()\n",
    "    filenames = [get_filepath(CITY) + fname for fname in hubway_stations_locations_filenames]\n",
    "    for filename in filenames:\n",
    "        new_df = pd.read_csv(filename)    \n",
    "        hubway_stations_locations_column_names = {\n",
    "            \"Station ID\": start_station_id,\n",
    "            \"Latitude\": start_station_latitude,\n",
    "            \"Longitude\": start_station_longitude,\n",
    "        }\n",
    "        # Rename the column names to match the rides data that the locations data will be joined with\n",
    "        new_df.rename(columns=hubway_stations_locations_column_names, inplace=True)\n",
    "        df = new_df if df.empty else df.append(new_df)\n",
    "    df.drop_duplicates(subset=[start_station_id], inplace=True)\n",
    "    return df\n",
    "\n",
    "hubway_stations_locations_df = None\n",
    "if CITY == \"boston\":\n",
    "    hubway_stations_locations_df = get_hubway_stations_locations_df()\n",
    "\n",
    "\n",
    "def preprocess_boston_stations_df(df):\n",
    "    if start_station_latitude in df.columns:\n",
    "        return df\n",
    "    # Otherwise this is one of the datasets that is lacking lat, lon info.\n",
    "    # Add the lat,lon info\n",
    "    return hubway_stations_locations_df.merge(df, on=start_station_id)\n",
    "\n",
    "\n",
    "\n",
    "# hubway_stations_locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-capitalbikeshare-tripdata.zip\n",
      "0 : handling file 2010-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-capitalbikeshare-tripdata.zip\n",
      "1 : handling file 2011-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-capitalbikeshare-tripdata.zip\n",
      "2 : handling file 2012-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-capitalbikeshare-tripdata.zip\n",
      "3 : handling file 2013-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-capitalbikeshare-tripdata.zip\n",
      "4 : handling file 2014-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-capitalbikeshare-tripdata.zip\n",
      "5 : handling file 2015-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-capitalbikeshare-tripdata.zip\n",
      "6 : handling file 2016-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-capitalbikeshare-tripdata.zip\n",
      "7 : handling file 2017-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n",
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201801-capitalbikeshare-tripdata.zip\n",
      "8 : handling file 201801-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201802-capitalbikeshare-tripdata.zip\n",
      "9 : handling file 201802-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201803-capitalbikeshare-tripdata.zip\n",
      "10 : handling file 201803-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201804-capitalbikeshare-tripdata.zip\n",
      "11 : handling file 201804-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201805-capitalbikeshare-tripdata.zip\n",
      "12 : handling file 201805-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201806-capitalbikeshare-tripdata.zip\n",
      "13 : handling file 201806-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201807-capitalbikeshare-tripdata.zip\n",
      "14 : handling file 201807-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201808-capitalbikeshare-tripdata.zip\n",
      "15 : handling file 201808-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201809-capitalbikeshare-tripdata.zip\n",
      "16 : handling file 201809-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201810-capitalbikeshare-tripdata.zip\n",
      "17 : handling file 201810-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201811-capitalbikeshare-tripdata.zip\n",
      "18 : handling file 201811-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201812-capitalbikeshare-tripdata.zip\n",
      "19 : handling file 201812-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201901-capitalbikeshare-tripdata.zip\n",
      "20 : handling file 201901-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201902-capitalbikeshare-tripdata.zip\n",
      "21 : handling file 201902-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201903-capitalbikeshare-tripdata.zip\n",
      "22 : handling file 201903-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201904-capitalbikeshare-tripdata.zip\n",
      "23 : handling file 201904-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201905-capitalbikeshare-tripdata.zip\n",
      "24 : handling file 201905-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201906-capitalbikeshare-tripdata.zip\n",
      "25 : handling file 201906-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201907-capitalbikeshare-tripdata.zip\n",
      "26 : handling file 201907-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201908-capitalbikeshare-tripdata.zip\n",
      "27 : handling file 201908-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201909-capitalbikeshare-tripdata.zip\n",
      "28 : handling file 201909-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201910-capitalbikeshare-tripdata.zip\n",
      "29 : handling file 201910-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201911-capitalbikeshare-tripdata.zip\n",
      "30 : handling file 201911-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201912-capitalbikeshare-tripdata.zip\n",
      "31 : handling file 201912-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202001-capitalbikeshare-tripdata.zip\n",
      "32 : handling file 202001-capitalbikeshare-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter\\AppData\\Local\\Temp\\ipykernel_11344\\344671069.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('[\\ ]', '')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'started_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Walter\\anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Walter\\anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Walter\\anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'started_at'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Walter\\Desktop\\bike_map\\income-race-bikes\\scripts\\bike_station_data_processing.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000004?line=66'>67</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000004?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m stations_df \u001b[39min\u001b[39;00m stations_dfs:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000004?line=70'>71</a>\u001b[0m     stations_df \u001b[39m=\u001b[39m preprocess_stations_df(stations_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000004?line=72'>73</a>\u001b[0m     unique_station_ids \u001b[39m=\u001b[39m stations_df[start_station_id]\u001b[39m.\u001b[39munique()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000004?line=73'>74</a>\u001b[0m     \u001b[39mfor\u001b[39;00m station_id \u001b[39min\u001b[39;00m unique_station_ids:\n",
      "\u001b[1;32mc:\\Users\\Walter\\Desktop\\bike_map\\income-race-bikes\\scripts\\bike_station_data_processing.ipynb Cell 4'\u001b[0m in \u001b[0;36mpreprocess_stations_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000003?line=7'>8</a>\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m ]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39m# transform the dates\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000003?line=10'>11</a>\u001b[0m df[starttime] \u001b[39m=\u001b[39m df[starttime]\u001b[39m.\u001b[39mapply(transform_date)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000003?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m CITY \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboston\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Walter/Desktop/bike_map/income-race-bikes/scripts/bike_station_data_processing.ipynb#ch0000003?line=12'>13</a>\u001b[0m     df \u001b[39m=\u001b[39m preprocess_boston_stations_df(df)\n",
      "File \u001b[1;32mc:\\Users\\Walter\\anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Walter\\anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Walter/anaconda3/envs/geo_env/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'started_at'"
     ]
    }
   ],
   "source": [
    "FILENAMES_TO_IGNORE = hubway_stations_locations_filenames + ['stations.csv'] + ['stations.json'] # + [more bad filenames here]\n",
    "\n",
    "\n",
    "def stations_dict_to_df(stations_dict):\n",
    "    new_dict = {\n",
    "        ID: [],\n",
    "        NAME: [],\n",
    "        LAT: [],\n",
    "        LON: [],\n",
    "        FIRST: [],\n",
    "        LAST: [],\n",
    "        RIDES: []\n",
    "    }\n",
    "    for station_id, station_dict in stations_dict.items():\n",
    "        new_dict[ID].append(station_id)\n",
    "        new_dict[NAME].append(station_dict[NAME])\n",
    "        new_dict[LAT].append(station_dict[LAT])\n",
    "        new_dict[LON].append(station_dict[LON])\n",
    "        new_dict[FIRST].append(station_dict[FIRST])\n",
    "        new_dict[LAST].append(station_dict[LAST])\n",
    "        new_dict[RIDES].append(station_dict[RIDES])\n",
    "    \n",
    "    return pd.DataFrame.from_dict(new_dict)\n",
    "    \n",
    "\n",
    "\n",
    "stations_dict = dict()\n",
    "needs_lat_lon = set()\n",
    "directory = get_filepath(CITY)\n",
    "files_count = 0\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    print(filename)\n",
    "    if filename in FILENAMES_TO_IGNORE:# or filename[:6] not in ['202102']:\n",
    "        continue\n",
    "    if filename[:4] in ['2021', '2022'] and filename[:6] not in ['202101'] and CITY == 'boston' or (filename[:4] in ['2020', '2021', '2022'] and filename[:6] not in ['202001', '202002', '202003']) and CITY == 'dc' :\n",
    "        start_station_id = 'start_station_id'\n",
    "        start_station_name = 'start_station_name'\n",
    "        start_station_latitude = 'start_lat'\n",
    "        start_station_longitude = 'start_lng'\n",
    "        starttime = 'started_at'\n",
    "    elif CITY != 'dc':\n",
    "        start_station_id = 'startstationid'\n",
    "        start_station_name = 'startstationname'\n",
    "        start_station_latitude = 'startstationlatitude'\n",
    "        start_station_longitude = 'startstationlongitude'\n",
    "        starttime = 'starttime'\n",
    "    else:\n",
    "        start_station_id = 'startstationid'\n",
    "        start_station_name = 'startstation'\n",
    "        start_station_latitude = \"\"\n",
    "        start_station_longitude = \"\"\n",
    "        starttime = \"starttime\"\n",
    "\n",
    "\n",
    "    fullfilename = directory + filename\n",
    "    print(files_count, ': handling file', filename)\n",
    "    files_count+=1\n",
    "    \n",
    "    if filename.endswith(\".csv\"):\n",
    "        stations_dfs = [pd.read_csv(fullfilename)]\n",
    "    elif filename.endswith(\".zip\") and CITY != 'dc':\n",
    "        stations_dfs = [open_zipfile(fullfilename)]\n",
    "    elif filename.endswith(\".zip\") and CITY == 'dc':\n",
    "        stations_dfs = [df for df in open_zipfile_dc(fullfilename)]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    for stations_df in stations_dfs:\n",
    "\n",
    "        stations_df = preprocess_stations_df(stations_df)\n",
    "        \n",
    "        unique_station_ids = stations_df[start_station_id].unique()\n",
    "        for station_id in unique_station_ids:\n",
    "            station_df = stations_df[stations_df[start_station_id] == station_id]\n",
    "            \n",
    "            if station_id not in stations_dict:\n",
    "                try:\n",
    "                    stations_dict[station_id] = {\n",
    "                        NAME: station_df[start_station_name].iloc[0], \n",
    "                        LAT: station_df[start_station_latitude].iloc[0],\n",
    "                        LON: station_df[start_station_longitude].iloc[0], \n",
    "                        FIRST: station_df[starttime].iloc[0], \n",
    "                        LAST: station_df[starttime].iloc[0],\n",
    "                        RIDES: 0,\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    if e == '':\n",
    "                        stations_dict[station_id] = {\n",
    "                            NAME: station_df[start_station_name].iloc[0], \n",
    "                            LAT: None,\n",
    "                            LON: None,\n",
    "                            FIRST: station_df[starttime].iloc[0], \n",
    "                            LAST: station_df[starttime].iloc[0],\n",
    "                            RIDES: 0,\n",
    "                        }\n",
    "                        needs_lat_lon.add(station_id)\n",
    "                    else:    \n",
    "                        continue\n",
    "            if station_id in needs_lat_lon and starttime == 'started_at':\n",
    "                stations_dict[station_id][LAT] = station_df[start_station_latitude].iloc[0]\n",
    "                stations_dict[station_id][LON] = station_df[start_station_longitude].iloc[0]\n",
    "                needs_lat_lon.remove(station_id)\n",
    "            rides_count = len(station_df.index)\n",
    "            stations_dict[station_id][RIDES] += rides_count\n",
    "            station_df = station_df.sort_values(by=[starttime])\n",
    "            if (station_df[starttime].iloc[0] < stations_dict[station_id][FIRST]):\n",
    "                stations_dict[station_id][FIRST] = stations_df[starttime].iloc[0]\n",
    "            if (station_df[starttime].iloc[-1] > stations_dict[station_id][LAST]):\n",
    "                stations_dict[station_id][LAST] = stations_df[starttime].iloc[-1]\n",
    "\n",
    "\n",
    "stations_df = stations_dict_to_df(stations_dict)\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the stations_df\n",
    "\n",
    "# Remove dummy stations (there are test stations in the data)\n",
    "# Remove stations with less than RIDES_COUNT_THRESHOLD rides\n",
    "bad_stations_df = stations_df[stations_df[RIDES] < RIDES_COUNT_THRESHOLD]\n",
    "print('removing %d bad stations that each have less than %d rides from stations data' % (bad_stations_df.shape[0], RIDES_COUNT_THRESHOLD))\n",
    "stations_df = stations_df[stations_df[RIDES] >= RIDES_COUNT_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_stations_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For the boston hubway/blue bikes data there will be duplicates because\n",
    "when management changed from hubway to Bluebikes, the data fromat did too\n",
    "This includes the station id/numbers and names AND lat/lon!\n",
    "Task: deduplicate stations\n",
    "\n",
    "Idea to understand data: sort the stations so the potential duplicates are next to each other\n",
    "when merging/deduping data make sure to keep the earliest first and the latest last.\n",
    "\n",
    "approach to deduplicating stations:\n",
    "- normalize names and add new temporary column with normalized name\n",
    "- get list of unique normalized names\n",
    "- for each name:\n",
    "    make a df for that name, sorted by [first, last]\n",
    "    update main df to replace entries with that name with:\n",
    "        first first\n",
    "        last last\n",
    "        last name\n",
    "        rides as sum of rides\n",
    "    sort main df by [name, first] and drop duplicates (duplicates on normalized name)\n",
    "    remove normalized name column\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "NORMALIZED_NAME = 'normalized_name'\n",
    "\n",
    "def normalized_station_name(name):\n",
    "    normalized_name = name.lower()\n",
    "    normalized_name = normalized_name.replace(\"former\",  \"\").replace(\" \", \"\")\n",
    "    normalized_name = re.sub(r'[^a-z0-9]','', normalized_name)\n",
    "    return normalized_name\n",
    "\n",
    "if CITY == 'boston':\n",
    "    stations_df[NORMALIZED_NAME] = stations_df[NAME].apply(normalized_station_name)\n",
    "    normalized_names = stations_df[NORMALIZED_NAME]\n",
    "    print(normalized_names.shape[0], ' names')\n",
    "    unique_normalized_names = stations_df[NORMALIZED_NAME].unique()\n",
    "    print(unique_normalized_names.shape[0], ' unique normalized names') #, unique_normalized_names)\n",
    "\n",
    "\n",
    "    n = 0\n",
    "    for normalized_name in unique_normalized_names:\n",
    "        print(n, 'handling name', normalized_name)\n",
    "        n+=1\n",
    "        name_df = stations_df[stations_df[NORMALIZED_NAME] == normalized_name]\n",
    "        name_df.sort_values(by=[FIRST, LAST], inplace=True)\n",
    "        first = name_df[FIRST].iloc[0]\n",
    "        last = name_df[LAST].iloc[-1]\n",
    "        name = name_df[NAME].iloc[-1]\n",
    "        rides = name_df[RIDES].sum()\n",
    "        update_condition = (stations_df[NORMALIZED_NAME] == normalized_name)\n",
    "        stations_df.loc[update_condition, [FIRST, LAST, NAME, RIDES]] = first, last, name, rides\n",
    "\n",
    "    stations_dropped_duplicates_df = stations_df.drop_duplicates(subset=[NORMALIZED_NAME])\n",
    "    print('dropped %s rows based on duplicate names' % (int(stations_df.shape[0]) - int(stations_dropped_duplicates_df.shape[0])))\n",
    "    stations_dropped_duplicates_df.drop(labels=[NORMALIZED_NAME], axis=1, inplace=True)\n",
    "    \n",
    "    stations_df = stations_dropped_duplicates_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_dropped_duplicates_df\n",
    "stations_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to CSV\n",
    "save_to_csvfilename = directory + 'stations.csv'\n",
    "stations_df.to_csv(save_to_csvfilename)\n",
    "print('wrote data to ', save_to_csvfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to JSON that will be used in web app\n",
    "import json\n",
    "\n",
    "stations = []\n",
    "for index, row in stations_df.iterrows():\n",
    "    # Transform the date\n",
    "    date = row[5]\n",
    "    \n",
    "    stations.append({\n",
    "        ID: str(row[ID]),\n",
    "        NAME: row[NAME],\n",
    "        LAT: row[LAT],\n",
    "        LON: row[LON],\n",
    "        FIRST: transform_date(row[FIRST]),\n",
    "        LAST: transform_date(row[LAST]),\n",
    "    })\n",
    "\n",
    "json = json.dumps(stations)\n",
    "\n",
    "save_to_jsonfilename = directory + 'stations.json'\n",
    "with open(save_to_jsonfilename, 'w') as f:\n",
    "    f.write(json)\n",
    "print(\"Data written to stations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "639955f742b38ffeb680f958c1dc9e296c7318d3e6d17e3c3dcc92b8320cf293"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
