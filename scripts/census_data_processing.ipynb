{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: update for state\n",
    "STATE = 'ny'\n",
    "YEARS = [str(yr) for yr in range(2013, 2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File naming convension for ACS 5-year downloads:\n",
    "state_year_[race|income].csv\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_filepath(state):\n",
    "    return '../data/{state}/'.format(state=state)\n",
    "\n",
    "def get_fname(state, year, dataset_type):\n",
    "    return '{state}_{year}_{dataset_type}.csv'.format(\n",
    "        state=state, year=year, dataset_type=dataset_type)\n",
    "\n",
    "def get_filename(state, year, dataset_type):\n",
    "    return get_filepath(state) + get_fname(state, year, dataset_type)\n",
    "\n",
    "\n",
    "# geoid is the column we join data on\n",
    "geoid_column_name = 'geoid'\n",
    "\n",
    "geoid_column_map = {\n",
    "    'GEO.id2': geoid_column_name,\n",
    "    'GEO_ID': geoid_column_name\n",
    "}\n",
    "\n",
    "# for some reason particular file(s) have different column names- WHY?!\n",
    "# filename_income_column_map = {\n",
    "#     'ma_2017_income.csv': {\n",
    "#         'HC03_EST_VC02': 'median income',\n",
    "#         'HC03_MOE_VC02': 'median income margin of error',\n",
    "#         'HD01_VD01': 'median income',\n",
    "#         'HD02_VD01': 'median income margin of error'\n",
    "#     }\n",
    "# }\n",
    "# Here is the default\n",
    "income_column_map = {\n",
    "    'HC02_EST_VC02': 'median income',\n",
    "    'HC02_MOE_VC02': 'median income margin of error',\n",
    "    'HD01_VD01': 'median income',\n",
    "    'HD02_VD01': 'median income margin of error'\n",
    "}\n",
    "\n",
    "new_income_map = {\n",
    "    'S1903_C03_001E': 'median income',\n",
    "    'S1903_C03_001M': 'median income margin of error'\n",
    "}\n",
    "\n",
    "new_income_map_early = {\n",
    "    'S1903_C02_001E': 'median income',\n",
    "    'S1903_C02_001M': 'median income margin of error'\n",
    "}\n",
    "\n",
    "race_column_map = {\n",
    "    'HD01_VD01': 'race: total households',\n",
    "    'HD02_VD01': 'race: total households margin of error',\n",
    "    'HD01_VD02': 'race: White',\n",
    "    'HD01_VD03': 'race: Black',\n",
    "    'HD01_VD05': 'race: Asian',\n",
    "    'HD01_VD08': 'race: 2 or more races',\n",
    "    # The following are combined into one value\n",
    "    # 'HD01_VD04': 'race: American Indian and Alaska',\n",
    "    # 'HD01_VD06': 'race: Native Hawaiian and Other',\n",
    "    'HD01_VD07': 'race: Other',\n",
    "}\n",
    "\n",
    "new_race_column_map = {\n",
    "    'B02001_001E': 'race: total households',\n",
    "    'B02001_001M': 'race: total households margin of error',\n",
    "    'B02001_002E': 'race: White',\n",
    "    'B02001_003E': 'race: Black',\n",
    "    'B02001_005E': 'race: Asian',\n",
    "    'B02001_008E': 'race: 2 or more races',\n",
    "    'B02001_007E': 'race: Other'\n",
    "}\n",
    "\n",
    "def race_combine_other(row):\n",
    "    \n",
    "    \"\"\"Combines the values for the other races with american indian, hawaiian, etc\"\"\"\n",
    "    try:\n",
    "        return int(row['HD01_VD04']) + int(row['HD01_VD06']) + int(row['HD01_VD07'])\n",
    "    except:\n",
    "        return int(row['B02001_004E']) + int(row['B02001_006E']) + int(row['B02001_007E'])\n",
    "\n",
    "def col_name_for_year(year, col_name):\n",
    "    return str(year) + ' ' + col_name\n",
    "\n",
    "def remove_labels(df):\n",
    "    # drop the first row (the first row is a display label)\n",
    "    df.drop([0], inplace=True)\n",
    "\n",
    "def preprocess_df(df, year, column_map):\n",
    "    # prune data\n",
    "    # data from 2018-onwards only has GEO_ID not GEO.id2\n",
    "    # if int(year) > 2017:\n",
    "    #     for num in range(1, df.shape[0]+1):\n",
    "    #         df.at[num, 'GEO_ID'] = df.at[num, 'GEO_ID'][-11:]\n",
    "    for num in range(1, df.shape[0]+1):\n",
    "        df.at[num, 'GEO_ID'] = df.at[num, 'GEO_ID'][-11:]  \n",
    "    # rename columns\n",
    "    column_name_map = {key: col_name_for_year(year, value) for key, value in column_map.items()}\n",
    "    \n",
    "    column_name_map.update(geoid_column_map)\n",
    "    cols_to_drop = [col for col in df.columns if not col in column_name_map.keys()]\n",
    "\n",
    "    df.drop(cols_to_drop,  axis=1,  inplace=True)\n",
    "    df.rename(columns=column_name_map, inplace=True)\n",
    "    df.set_index(geoid_column_name, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_race_df(state, year):\n",
    "    filename = get_filename(STATE, year, 'race')\n",
    "    df = pd.read_csv(filename)\n",
    "    remove_labels(df)\n",
    "    df['column'] = df.apply(race_combine_other, axis=1)\n",
    "    map = new_race_column_map\n",
    "    return preprocess_df(df, year, map)\n",
    "\n",
    "\n",
    "def get_income_df(state, year):\n",
    "    # so annoying that the columns change with files!\n",
    "    if int(year) >= 2017:\n",
    "        map = new_income_map\n",
    "    else:\n",
    "        map = new_income_map_early\n",
    "    fname = get_fname(state, year, 'income')\n",
    "    print('filename', fname)\n",
    "    # if fname in filename_income_column_map:\n",
    "    #     map = filename_income_column_map[fname]\n",
    "    df = pd.read_csv(get_filename(STATE, year, 'income'))\n",
    "    print('income:df', df)\n",
    "    remove_labels(df)\n",
    "    return preprocess_df(df, year, map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We merge data into the income df\n",
    "\n",
    "def add_df(df1, df2):\n",
    "    # comebine the df's on geoid\n",
    "    return pd.concat([df1, df2], axis=1, join='inner')\n",
    "\n",
    "state_df = None\n",
    "for year in YEARS:\n",
    "    print('handling files for year ', year)\n",
    "    income_df = get_income_df(STATE, year)\n",
    "    if state_df is None:\n",
    "        state_df = income_df\n",
    "    else:\n",
    "        state_df = add_df(state_df, income_df)\n",
    "    # print(state_df)\n",
    "    race_df = get_race_df(STATE, year)\n",
    "    state_df = add_df(state_df, race_df)\n",
    "# state_df = state_df.loc[state_df[geoid_column_name] == '48201410802']\n",
    "state_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the giant dataframe to CSV\n",
    "output_csvfilename = get_filepath(STATE) + 'race_and_income_data.csv'\n",
    "state_df.to_csv(output_csvfilename)\n",
    "print('saved data to ',  output_csvfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creates shapefile from NYC open data download.\n",
    "This shapefile does not have geoids, so must add them based on its other data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NY_STATE_CODE = '36'\n",
    "\n",
    "nyc_shapefile_attributes = {\n",
    "    geoid_column_name: geoid_column_name,\n",
    "    'ntaname': 'Name', # name of neighborhood in this dataset\n",
    "    # Tracts are duplicated across boros.\n",
    "    # The unique key is 'boro_ct201' which is the concatenation of boro id and ct\n",
    "    # 'ct2010': 'tract',\n",
    "    'shape_area': 'shape_area',\n",
    "    'shape_leng': 'shape_leng',\n",
    "    'geometry': 'geometry'\n",
    "}\n",
    "ma_shapefile_attributes = {\n",
    "    'GEOID10': geoid_column_name,\n",
    "    'NAMELSAD10': 'Name', # 'Census Tract ###'  in this dataset\n",
    "    'SHAPE_AREA': 'shape_area',\n",
    "    'SHAPE_LEN': 'shape_leng',\n",
    "    'geometry': 'geometry'\n",
    "}\n",
    "\n",
    "tiger_shapefile_attributes = {\n",
    "    'GEOID': geoid_column_name,\n",
    "    'NAMELSAD': 'Name',\n",
    "    'AREA': 'shape_area',\n",
    "    'geometry': 'geometry'\n",
    "}\n",
    "\n",
    "# Mapping of boro names to county code for geoid\n",
    "# Taken from wikipedia info: https://en.wikipedia.org/wiki/List_of_counties_in_New_York\n",
    "nyc_boro_to_county_code = {\n",
    "    'Bronx':'005',\n",
    "    'Queens':'081',\n",
    "    'Brooklyn':'047',\n",
    "    'Manhattan':'061',\n",
    "    'Staten Island':'085'\n",
    "}\n",
    "\n",
    "\n",
    "def get_nyc_shapefile():\n",
    "    shapefile_filename = get_filepath('ny') + 'city_census_tracts_shapefile/geo_export_6f3df1e4-1be2-4395-ba6c-3e15b0a10221.shp'\n",
    "    shapefile_df = gpd.read_file(shapefile_filename)\n",
    "    shapefile_df[geoid_column_name] = shapefile_df.apply(get_nyc_geoid, axis=1)\n",
    "    return shapefile_df\n",
    "\n",
    "\n",
    "def get_nyc_county_code(row):\n",
    "    boro_name = row['boro_name']\n",
    "    return nyc_boro_to_county_code[boro_name]\n",
    "\n",
    "\n",
    "def get_nyc_geoid(row):\n",
    "    state_code = NY_STATE_CODE\n",
    "    county_code = get_nyc_county_code(row)\n",
    "    tract_code = row['ct2010']\n",
    "    return str(state_code) + str(county_code) + str(tract_code)\n",
    "\n",
    "shapefile_df = None\n",
    "if STATE == 'ny':\n",
    "    shapefile_df = get_nyc_shapefile()\n",
    "    shapefile_attributes = nyc_shapefile_attributes\n",
    "elif STATE == 'ma':\n",
    "    shapefile_filename = get_filepath(STATE) + 'shapefile/boston-brookline-cambridge-somerville-everett.shp'\n",
    "    shapefile_df = gpd.read_file(shapefile_filename)\n",
    "    shapefile_attributes = ma_shapefile_attributes\n",
    "elif STATE == 'dc':\n",
    "    shapefile_filename = get_filepath(STATE) + 'shapefile/DC/tl_2019_11_tract.shp'\n",
    "    dc_shapefile_df = gpd.read_file(shapefile_filename)\n",
    "\n",
    "    shapefile_filename = get_filepath(STATE) + 'shapefile/MD/tl_2019_24_tract.shp'\n",
    "    md_shapefile_df = gpd.read_file(shapefile_filename)\n",
    "    md_shapefile_df1 = md_shapefile_df.loc[md_shapefile_df[\"COUNTYFP\"] == '031']\n",
    "    md_shapefile_df2 = md_shapefile_df.loc[md_shapefile_df[\"COUNTYFP\"] == '033']\n",
    "    md_shapefile_df = pd.concat([md_shapefile_df1, md_shapefile_df2], axis = 0)\n",
    "\n",
    "    shapefile_filename = get_filepath(STATE) + 'shapefile/VA/tl_2019_51_tract.shp'\n",
    "    va_shapefile_df = gpd.read_file(shapefile_filename)\n",
    "    va_shapefile_df1 = va_shapefile_df.loc[va_shapefile_df[\"COUNTYFP\"] == '013']\n",
    "    va_shapefile_df2 = va_shapefile_df.loc[va_shapefile_df[\"COUNTYFP\"] == '510']\n",
    "    va_shapefile_df = pd.concat([va_shapefile_df1, va_shapefile_df2], axis = 0)\n",
    "\n",
    "    shapefile_df = pd.concat([dc_shapefile_df, va_shapefile_df, md_shapefile_df], axis = 0)\n",
    "    shapefile_df[\"AREA\"] = shapefile_df[\"ALAND\"].astype(int) + shapefile_df[\"AWATER\"].astype(int)\n",
    "    shapefile_attributes = tiger_shapefile_attributes\n",
    "\n",
    "elif STATE == 'il':\n",
    "    shapefile_filename = get_filepath(STATE) + 'shapefile/tl_2019_17_tract.shp'\n",
    "    shapefile_df = gpd.read_file(shapefile_filename)\n",
    "    shapefile_df = shapefile_df.loc[shapefile_df[\"COUNTYFP\"] == '031']\n",
    "    shapefile_df[\"AREA\"] = shapefile_df[\"ALAND\"].astype(int) + shapefile_df[\"AWATER\"].astype(int)\n",
    "    shapefile_attributes = tiger_shapefile_attributes\n",
    "elif STATE == 'pa':\n",
    "    shapefile_filename = get_filepath(STATE) + 'shapefiles/tl_2019_42_tract.shp'\n",
    "    shapefile_df = gpd.read_file(shapefile_filename)\n",
    "    shapefile_df = shapefile_df.loc[shapefile_df[\"COUNTYFP\"] == '101']\n",
    "    shapefile_df[\"AREA\"] = shapefile_df[\"ALAND\"].astype(int) + shapefile_df[\"AWATER\"].astype(int)\n",
    "    shapefile_attributes = tiger_shapefile_attributes\n",
    "\n",
    "shapefile_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map column names and remove columns\n",
    "shapefile_cols_to_drop = [col for col in shapefile_df.columns if not col in shapefile_attributes.keys()]\n",
    "shapefile_df.drop(shapefile_cols_to_drop,  axis=1,  inplace=True)\n",
    "shapefile_df.rename(columns=shapefile_attributes, inplace=True)\n",
    "shapefile_df.head()\n",
    "shapefile_df.set_index(geoid_column_name, inplace=True)\n",
    "shapefile_df.head() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want projection CRS84 which is equivalent to EPSG:4326\n",
    "shapefile_df = shapefile_df.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "%matplotlib inline\n",
    "shapefile_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_shapes = shapefile_df.merge(state_df, on=geoid_column_name)\n",
    "print('shape', merged_shapes.shape)\n",
    "merged_shapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_filename = get_filepath(STATE) + STATE  + '_census_tracts.geojson'\n",
    "print('saving to ',to_filename)\n",
    "merged_shapes[\"geometry\"] = [MultiPolygon([feature]) if type(feature) == Polygon \\\n",
    "    else feature for feature in merged_shapes[\"geometry\"]]\n",
    "merged_shapes.to_file(to_filename, driver='GeoJSON')\n",
    "print('saved')\n",
    "sort = False"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "639955f742b38ffeb680f958c1dc9e296c7318d3e6d17e3c3dcc92b8320cf293"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
